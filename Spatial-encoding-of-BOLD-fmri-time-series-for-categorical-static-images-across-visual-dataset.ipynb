{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jS4OGAsoOyLX",
        "vZeuMZJTPAb3",
        "_Ko-7qdoQOvo",
        "rF-PFQYMvZiX",
        "IyskU1KWp4Uc",
        "jyVzgUbqSJ5l",
        "Ocl0lC5DMBtt",
        "IwG8GEnlSl68",
        "jH7J0o_ySuYs",
        "19OqTa1KSxKf",
        "NM-6ScwsSytp",
        "sTDcpVawS0eM"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "libraries"
      ],
      "metadata": {
        "id": "h7mnGWSNO7DW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blXaTL5mOwei"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pyts.image import MarkovTransitionField\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "from tensorflow.keras.models import Sequential,load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten,Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import roc_curve,auc\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.patches as patches\n",
        "from scipy import interp\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from pyts.image import GramianAngularField\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D,Conv1D, Concatenate,Dense, Dropout, Flatten\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#cnn model"
      ],
      "metadata": {
        "id": "jS4OGAsoOyLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##functions"
      ],
      "metadata": {
        "id": "vZeuMZJTPAb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reset index\n",
        "def res_ind(df):\n",
        "  df=df.reset_index()\n",
        "  df=df.drop(['index'], axis=1)\n",
        "  return df"
      ],
      "metadata": {
        "id": "sn7dJi7RO9I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## binary classification model\n",
        "def Model_1():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (2, 2), activation='relu', input_shape=(16, 16,1)) )\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (2, 2), activation='relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(8,activation='relu'))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.compile(optimizer=Adam(learning_rate=0.001),loss='binary_crossentropy',\n",
        "                metrics=['accuracy','Precision','Recall'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "yS0TGpzfPCay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Kfloding(kf,model,x,y,floder_path,model_file,subject,epochs,batch_size):\n",
        "  callback_2 = ModelCheckpoint(floder_path +str(subject)+'__'+str(model_file)+'.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "  callback_3 = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.001 * np.exp(-epoch / 10.))\n",
        "  callback_1 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "  cv = StratifiedKFold(n_splits=int(kf),shuffle=True,random_state=98)\n",
        "  #fig1 = plt.figure(figsize=[12,12])\n",
        "  #ax1 = fig1.add_subplot(111,aspect = 'equal')\n",
        "  accuracy_v=[]\n",
        "  y_true=[]\n",
        "  y_predict = []\n",
        "  tprs = []\n",
        "  aucs = []\n",
        "  mean_fpr = np.linspace(0,1,100)\n",
        "  i = 1\n",
        "  for train_index,test_index in cv.split(x,y):\n",
        "      x_train,x_test=x[train_index],x[test_index]\n",
        "      y_train,y_test=y[train_index],y[test_index]\n",
        "      model.fit(x_train, y_train,batch_size=batch_size,\n",
        "                          epochs=epochs,\n",
        "                          validation_data=(x_test,y_test),\n",
        "                          callbacks=[callback_2])\n",
        "      model = load_model(floder_path +str(subject)+'__'+str(model_file)+'.h5')\n",
        "      print('Model evaluation ',model.evaluate(x_test,y_test))\n",
        "      loss,accuracy,precision,recall_1=model.evaluate(x_test,y_test)\n",
        "      print('kf_fold',i,\" \", 'loss',loss,'Accurary',accuracy,'Precision',precision,'Recall',recall_1)\n",
        "      i=i+1\n",
        "      accuracy_v.append(accuracy)\n",
        "  return accuracy_v,sum(accuracy_v)/10\n"
      ],
      "metadata": {
        "id": "FsCgiZjGPMFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mark_img(dat):\n",
        "  mtf = MarkovTransitionField(image_size=16)\n",
        "  MTF = mtf.fit_transform(dat.iloc[:,:-1])\n",
        "  x = MTF.reshape(MTF.shape[0], 16, 16,1)\n",
        "  y=dat['label']\n",
        "  return x,y\n"
      ],
      "metadata": {
        "id": "NF_S5fZ1PR59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gram_diff(dat):\n",
        "  gram = GramianAngularField(image_size=16, method='difference')\n",
        "  gram_t = gram.fit_transform(dat.iloc[:,:-1])\n",
        "  x = gram_t.reshape(gram_t.shape[0], 16, 16,1)\n",
        "  y=dat['label']\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "a0VtArmVPj5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gram_summ(dat):\n",
        "  gram = GramianAngularField(image_size=16, method='summation')\n",
        "  gram_t = gram.fit_transform(dat.iloc[:,:-1])\n",
        "  x = gram_t.reshape(gram_t.shape[0], 16, 16,1)\n",
        "  y=dat['label']\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "0WbieUwFPlc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kf_flod_three(kf,x,y,floder_path,model_file,subject,epochs,batch_size):\n",
        "    model1 = Sequential()\n",
        "    model1.add(Conv2D(32, (2, 2), activation='relu', input_shape=(16, 16,1)))\n",
        "    model1.add(MaxPooling2D((2, 2)))\n",
        "    model1.add(Conv2D(64, (2, 2), activation='relu'))\n",
        "    model1.add(MaxPooling2D((2, 2)))\n",
        "    model1.add(Flatten())\n",
        "    model1.add(Dense(32, activation='relu'))\n",
        "    model1.add(Dense(8,activation='relu'))\n",
        "    model1.add(Dense(3,activation='softmax'))\n",
        "    model1.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy','Precision','Recall'])\n",
        "\n",
        "    callback_2 = ModelCheckpoint(floder_path +str(subject)+'__'+str(model_file)+'.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "    callback_3 = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.001 * np.exp(-epoch / 10.))\n",
        "    callback_1 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=int(kf),shuffle=True,random_state=98)\n",
        "    #fig1 = plt.figure(figsize=[12,12])\n",
        "    #ax1 = fig1.add_subplot(111,aspect = 'equal')\n",
        "    accuracy_v=[]\n",
        "    y_true=[]\n",
        "    y_predict = []\n",
        "    pred_probs=[]\n",
        "    tprs = []\n",
        "    aucs = []\n",
        "    fold_no=0\n",
        "    #y_tf = tf.keras.utils.to_categorical(y, num_classes = 3)\n",
        "    i=1\n",
        "    for train_index,test_index in cv.split(x,y):\n",
        "        x_train,x_test=x[train_index],x[test_index]\n",
        "        y_train,y_test=y[train_index],y[test_index]\n",
        "        y_train = tf.keras.utils.to_categorical(y_train, num_classes = 3)\n",
        "        y_test = tf.keras.utils.to_categorical(y_test, num_classes = 3)\n",
        "\n",
        "        model1.fit(x_train, y_train,batch_size=batch_size,\n",
        "                            epochs=epochs,\n",
        "                            validation_data=(x_test,y_test),\n",
        "                            callbacks=[callback_2])\n",
        "        model1 = load_model(floder_path +str(subject)+'__'+str(model_file)+'.h5')\n",
        "        #scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "        #print(scores)\n",
        "        #print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "        #   print(\"***************************************************\\n\")\n",
        "        loss,accuracy,precision,recall_1=model1.evaluate(x_test,y_test)\n",
        "        print('kf_fold',i,\" \", 'loss',loss,'Accurary',accuracy,'Precision',precision,'Recall',recall_1)\n",
        "        i=i+1\n",
        "        accuracy_v.append(accuracy)\n",
        "    return accuracy_v,sum(accuracy_v)/10\n"
      ],
      "metadata": {
        "id": "UqMYAytuP1Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##subject"
      ],
      "metadata": {
        "id": "_Ko-7qdoQOvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Here we showed with one subject for markov transitionfield, you can check other subjects by changing the input path (.csv file) and  replacing mark_img() function with gram_diff(),gram_summ() for FMRI_GramianAngularField.***"
      ],
      "metadata": {
        "id": "hatNVNrYQueC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coc_1=pd.read_csv('/content/Final_data_Split/Subject1/COCO.csv')\n",
        "img_1=pd.read_csv('/content/Final_data_Split/Subject1/ImageNet.csv')\n",
        "sun_1=pd.read_csv('/content/Final_data_Split/Subject1/SUN.csv')"
      ],
      "metadata": {
        "id": "gy-t84wOQQbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('/content/out1')"
      ],
      "metadata": {
        "id": "YnqHG30uQR__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch=8"
      ],
      "metadata": {
        "id": "6stQ9sHOQTZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y_p2M_uzQV9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**COCO_vs_sun**"
      ],
      "metadata": {
        "id": "mbb-QcRJbVSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_c=coc_1.iloc[:,:16]\n",
        "df_c['label']=0 #COCO\n",
        "\n",
        "df_s=sun_1.iloc[:,:16]\n",
        "df_s['label']=1 #SUN\n",
        "df_C_S=pd.concat([df_c,df_s])\n",
        "df_C_S=res_ind(df_C_S)\n"
      ],
      "metadata": {
        "id": "q98on69wbSYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=mark_img(df_C_S)\n",
        "x.shape,y.shape"
      ],
      "metadata": {
        "id": "618dIMjvbSVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Model_1()\n",
        "kf=10\n",
        "floder_path='/content/out1/'\n",
        "model_file='model_coco_vs_sun'\n",
        "Kfloding(kf,model_1,x,y,floder_path,model_file,'subject_1',20,batch)"
      ],
      "metadata": {
        "id": "a2XPTWWMbSSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Imagenet_vs_sun**"
      ],
      "metadata": {
        "id": "rF-PFQYMvZiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_i=img_1.iloc[:,:16]\n",
        "df_i['label']=0 #COCO\n",
        "\n",
        "df_s=sun_1.iloc[:,:16]\n",
        "df_s['label']=1 #SUN\n",
        "df_I_S=pd.concat([df_i,df_s])\n",
        "df_I_S=res_ind(df_I_S)\n"
      ],
      "metadata": {
        "id": "slOisoG9vZig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=mark_img(df_I_S)\n",
        "x.shape,y.shape"
      ],
      "metadata": {
        "id": "b0QqDZRQvZih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Model_1()\n",
        "kf=10\n",
        "floder_path='/content/out1/'\n",
        "model_file='model_image_vs_sun'\n",
        "Kfloding(kf,model_1,x,y,floder_path,model_file,'subject_1',20,batch)"
      ],
      "metadata": {
        "id": "wQbhZSBBvZii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qgDemOtBjKdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**coco_vs_imagenet**\n"
      ],
      "metadata": {
        "id": "IyskU1KWp4Uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_i=img_1.iloc[:,:16]\n",
        "df_i['label']=0 #img\n",
        "\n",
        "df_c=coc_1.iloc[:,:16]\n",
        "df_c['label']=1 #coco\n",
        "df_I_C=pd.concat([df_c,df_i])\n",
        "df_I_C=res_ind(df_I_C)\n"
      ],
      "metadata": {
        "id": "JNPyfstHp-5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=mark_img(df_I_C)\n",
        "x.shape,y.shape"
      ],
      "metadata": {
        "id": "gAL3HPWSqDEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Model_1()\n",
        "kf=10\n",
        "floder_path='/content/out1/'\n",
        "model_file='model_coco_vs_imagenet'\n",
        "Kfloding(kf,model_1,x,y,floder_path,model_file,'subject_1',50,batch)"
      ],
      "metadata": {
        "id": "-dYjBAExqFJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v-X0U2Z9qC3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###coco_vs_imagenet_vs_sun"
      ],
      "metadata": {
        "id": "oGEEd1ErqMlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_c=coc_1.iloc[:,:16]\n",
        "df_c['label']=0\n",
        "df_i=img_1.iloc[:,:16]\n",
        "df_i['label']=1\n",
        "df_s=sun_1.iloc[:,:16]\n",
        "df_s['label']=2\n",
        "df_total=pd.concat([df_i,df_c,df_s])\n",
        "df_total=res_ind(df_total)\n",
        "dat = df_total.copy()"
      ],
      "metadata": {
        "id": "vuuA-2rsqQtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=mark_img(dat)\n",
        "x.shape,y.shape"
      ],
      "metadata": {
        "id": "rT8lZMk_qUyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_1 = Model_1()\n",
        "kf=10\n",
        "floder_path='/content/out1/'\n",
        "model_file='model_coco_vs_imagenet_sun'\n",
        "kf_flod_three(kf,x,y,floder_path,model_file,'subject_1',50,batch)\n"
      ],
      "metadata": {
        "id": "zckn1ZZaqbEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ECxsZfjDSJCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#parallel cnn"
      ],
      "metadata": {
        "id": "jyVzgUbqSJ5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##functions"
      ],
      "metadata": {
        "id": "Ocl0lC5DMBtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interpolation(data):\n",
        "  data1=data.iloc[:,:16]\n",
        "  data1 = data1.replace(0,np.nan)\n",
        "  data2=data1.T\n",
        "  data2.reset_index(inplace=True)\n",
        "  s1 = data2.interpolate(method='spline',order=1)\n",
        "  s1.drop(['index'],axis=1,inplace=True)\n",
        "  s2 = s1.T\n",
        "  return s2"
      ],
      "metadata": {
        "id": "AVuOs38ORBpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reset index\n",
        "def res_ind(df):\n",
        "  df=df.reset_index()\n",
        "  df=df.drop(['index'], axis=1)\n",
        "  return df"
      ],
      "metadata": {
        "id": "Eeu5meilMEuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Model_par_two():\n",
        "    input_1 = Input(shape=(16,16,1))\n",
        "    input_2 = Input(shape=(16,16,1))\n",
        "    input_3 = Input(shape=(16,16,1))\n",
        "\n",
        "\n",
        "    # First parallel convolutional network\n",
        "    conv_1 = Conv2D(filters=32, kernel_size=(2,2), activation='relu')(input_1)\n",
        "    # Additional layers for the first parallel network\n",
        "    max_p_1=MaxPooling2D((2, 2))(conv_1)\n",
        "    conv_2 = Conv2D(filters=64, kernel_size=(2,2), activation='relu')(max_p_1)\n",
        "    max_p_2=MaxPooling2D((2, 2))(conv_2)\n",
        "\n",
        "    # Second parallel convolutional network\n",
        "    conv_11 = Conv2D(filters=32, kernel_size=(2,2), activation='relu')(input_2)\n",
        "    # Additional layers for the second parallel network\n",
        "    max_p_11=MaxPooling2D((2, 2))(conv_11)\n",
        "    conv_22 = Conv2D(filters=64, kernel_size=(2,2), activation='relu')(max_p_11)\n",
        "    max_p_22=MaxPooling2D((2, 2))(conv_22)\n",
        "\n",
        "    # Second parallel convolutional network\n",
        "    conv_3 = Conv2D(filters=32, kernel_size=(2,2), activation='relu')(input_3)\n",
        "    # Additional layers for the second parallel network\n",
        "    max_p_31=MaxPooling2D((2, 2))(conv_3)\n",
        "    conv_32 = Conv2D(filters=64, kernel_size=(2,2), activation='relu')(max_p_31)\n",
        "    max_p_33=MaxPooling2D((2, 2))(conv_32)\n",
        "\n",
        "\n",
        "\n",
        "    # Concatenate the output tensors from both parallel networks\n",
        "    merged = Concatenate()([max_p_2, max_p_22,max_p_33])\n",
        "\n",
        "    # Additional layers or operations on the merged output\n",
        "    merged_1 = Flatten()(merged)\n",
        "    merged_22 = Dense(128,activation='relu')(merged_1)\n",
        "    merged_2 = Dense(32,activation='relu')(merged_22)\n",
        "\n",
        "    merged_3 = Dense(8,activation='relu')(merged_2)\n",
        "    merged_4 = Dense(1,activation='sigmoid')(merged_3)\n",
        "\n",
        "    # Create the model\n",
        "    model = tf.keras.models.Model(inputs=[input_1, input_2,input_3], outputs=merged_4)\n",
        "    # Compile the model and specify loss function, optimizer, etc.\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy','Precision','Recall'])\n",
        "    # Print the model summary\n",
        "    #model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "y6So51Wg9VLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Kfloding(kf,model,x,y,x1,y1,x2,y2,floder_path,model_file,subject,epochs,batch_size):\n",
        "  callback_2 = ModelCheckpoint(floder_path +str(subject)+'__'+str(model_file)+'.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "  callback_3 = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.001 * np.exp(-epoch / 10.))\n",
        "  callback_1 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
        "\n",
        "  cv = StratifiedKFold(n_splits=int(kf),shuffle=True,random_state=98)\n",
        "  #fig1 = plt.figure(figsize=[12,12])\n",
        "  #ax1 = fig1.add_subplot(111,aspect = 'equal')\n",
        "  accuracy_v=[]\n",
        "  y_true=[]\n",
        "  y_predict = []\n",
        "  tprs = []\n",
        "  aucs = []\n",
        "  mean_fpr = np.linspace(0,1,100)\n",
        "  i = 1\n",
        "  for train_index,test_index in cv.split(x,y):\n",
        "      x_train,x_test=x[train_index],x[test_index]\n",
        "      y_train,y_test=y[train_index],y[test_index]\n",
        "\n",
        "      x_train_1,x_test_1=x1[train_index],x1[test_index]\n",
        "      y_train_1,y_test_1=y1[train_index],y1[test_index]\n",
        "\n",
        "      x_train_2,x_test_2=x2[train_index],x2[test_index]\n",
        "      y_train_2,y_test_2=y2[train_index],y2[test_index]\n",
        "\n",
        "      model.fit([x_train, x_train_1,x_train_2], y_train,batch_size=batch_size,\n",
        "                          epochs=epochs,\n",
        "                          validation_data=([x_test,x_test_1,x_test_2],y_test),\n",
        "                          callbacks=[callback_2])\n",
        "      model = load_model(floder_path +str(subject)+'__'+str(model_file)+'.h5')\n",
        "      print('Model evaluation ',model.evaluate([x_test,x_test_1,x_test_2],y_test))\n",
        "      loss,accuracy,precision,recall_1=model.evaluate([x_test,x_test_1,x_test_2],y_test)\n",
        "      print('kf_fold',i,\" \", 'loss',loss,'Accurary',accuracy,'Precision',precision,'Recall',recall_1)\n",
        "      accuracy_v.append(accuracy)\n",
        "  return accuracy_v,sum(accuracy_v)/10\n"
      ],
      "metadata": {
        "id": "3vqEZpc8O0eK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "62987487-9c6e-4c57-d7bb-1d34b96af65d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n      res = model.evaluate(x_test,y_test)\\n      #accuracy.append(res[1] * 100)\\n      prediction = model.predict(x_test)\\n      y_pred1 = (model.predict(x_test) > 0.5).astype(int)\\n      #y_pred1 = np.array(prediction >= 0.5, dtype = int)\\n      y_predict.append(y_pred1)\\n      y_true.append(y_test)\\n\\n      fpr, tpr, t = roc_curve(y_test, prediction)\\n      tprs.append(interp(mean_fpr, fpr, tpr))\\n      roc_auc = auc(fpr, tpr)\\n      aucs.append(roc_auc)\\n      #plt.plot(fpr, tpr, lw=2, alpha=0.3, label=\\'ROC fold %d (AUC = %0.2f)\\' % (i, roc_auc))\\n      i= i+1\\n\\n\\n  mean_tpr = np.mean(tprs, axis=0)\\n  mean_auc = auc(mean_fpr, mean_tpr)\\n  plt.plot(mean_fpr, mean_tpr, color=\\'blue\\',\\n          label=r\\'Mean ROC (AUC = %0.2f )\\' % (mean_auc),lw=2,)# alpha=1)\\n\\n  plt.plot([0,1],[0,1],\\'k--\\',lw = 2)\\n  plt.xlim([0.0, 1.0])\\n  plt.ylim([0.0, 1.05])\\n  plt.xlabel(\\'False Positive Rate\\')\\n  plt.ylabel(\\'True Positive Rate\\')\\n  plt.title(\\'ROC\\')\\n  plt.legend(loc=\"lower right\")\\n  plt.savefig(floder_path +str(subject)+\\'__\\'+str(model_file)+\\'.png\\')\\n\\n  plt.show()\\n  return accuracy,y_true,y_predict\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Model_par_three():\n",
        "    input_1 = Input(shape=(16,16,1))\n",
        "    input_2 = Input(shape=(16,16,1))\n",
        "    input_3 = Input(shape=(16,16,1))\n",
        "\n",
        "\n",
        "    # First parallel convolutional network\n",
        "    conv_1 = Conv2D(filters=32, kernel_size=(2,2), activation='relu')(input_1)\n",
        "    # Additional layers for the first parallel network\n",
        "    max_p_1=MaxPooling2D((2, 2))(conv_1)\n",
        "    conv_2 = Conv2D(filters=64, kernel_size=(2,2), activation='relu')(max_p_1)\n",
        "    max_p_2=MaxPooling2D((2, 2))(conv_2)\n",
        "\n",
        "    # Second parallel convolutional network\n",
        "    conv_11 = Conv2D(filters=32, kernel_size=(2,2), activation='relu')(input_2)\n",
        "    # Additional layers for the second parallel network\n",
        "    max_p_11=MaxPooling2D((2, 2))(conv_11)\n",
        "    conv_22 = Conv2D(filters=64, kernel_size=(2,2), activation='relu')(max_p_11)\n",
        "    max_p_22=MaxPooling2D((2, 2))(conv_22)\n",
        "\n",
        "    # Second parallel convolutional network\n",
        "    conv_3 = Conv2D(filters=32, kernel_size=(2,2), activation='relu')(input_3)\n",
        "    # Additional layers for the second parallel network\n",
        "    max_p_31=MaxPooling2D((2, 2))(conv_3)\n",
        "    conv_32 = Conv2D(filters=64, kernel_size=(2,2), activation='relu')(max_p_31)\n",
        "    max_p_33=MaxPooling2D((2, 2))(conv_32)\n",
        "\n",
        "\n",
        "\n",
        "    # Concatenate the output tensors from both parallel networks\n",
        "    merged = Concatenate()([max_p_2, max_p_22,max_p_33])\n",
        "\n",
        "    # Additional layers or operations on the merged output\n",
        "    merged_1 = Flatten()(merged)\n",
        "    merged_22 = Dense(128,activation='relu')(merged_1)\n",
        "    merged_2 = Dense(32,activation='relu')(merged_22)\n",
        "    merged_3 = Dense(8,activation='relu')(merged_2)\n",
        "    merged_4 = Dense(3,activation='softmax')(merged_3)\n",
        "\n",
        "    # Create the model\n",
        "    model = tf.keras.models.Model(inputs=[input_1, input_2,input_3], outputs=merged_4)\n",
        "    # Compile the model and specify loss function, optimizer, etc.\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy','Precision','Recall'])\n",
        "    # Print the model summary\n",
        "    #model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "ptZpBkSO9z16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mark_img(dat):\n",
        "  mtf = MarkovTransitionField(image_size=16)\n",
        "  MTF = mtf.fit_transform(dat.iloc[:,:-1])\n",
        "  x = MTF.reshape(MTF.shape[0], 16, 16,1)\n",
        "  y=dat['label']\n",
        "  return x,y\n"
      ],
      "metadata": {
        "id": "qC1GeJUznmrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gram_diff(dat):\n",
        "  gram = GramianAngularField(image_size=16, method='difference')\n",
        "  gram_t = gram.fit_transform(dat.iloc[:,:-1])\n",
        "  x = gram_t.reshape(gram_t.shape[0], 16, 16,1)\n",
        "  y=dat['label']\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "TX2Og-gWb6jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gram_summ(dat):\n",
        "  gram = GramianAngularField(image_size=16, method='summation')\n",
        "  gram_t = gram.fit_transform(dat.iloc[:,:-1])\n",
        "  x = gram_t.reshape(gram_t.shape[0], 16, 16,1)\n",
        "  y=dat['label']\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "yl230_Bv-hj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kf_flod_three(kf,x,y,x1,y1,x2,y2,model1,floder_path,model_file,subject,epochs,batch_size):\n",
        "\n",
        "    callback_2 = ModelCheckpoint(floder_path +str(subject)+'__'+str(model_file)+'.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "    callback_3 = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.001 * np.exp(-epoch / 10.))\n",
        "    callback_1 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=int(kf),shuffle=True,random_state=98)\n",
        "    #fig1 = plt.figure(figsize=[12,12])\n",
        "    #ax1 = fig1.add_subplot(111,aspect = 'equal')\n",
        "    accuracy_v=[]\n",
        "    y_true=[]\n",
        "    y_predict = []\n",
        "    pred_probs=[]\n",
        "    tprs = []\n",
        "    aucs = []\n",
        "    fold_no=0\n",
        "    #y_tf = tf.keras.utils.to_categorical(y, num_classes = 3)\n",
        "    i=1\n",
        "    for train_index,test_index in cv.split(x,y):\n",
        "        x_train,x_test=x[train_index],x[test_index]\n",
        "        y_train,y_test=y[train_index],y[test_index]\n",
        "\n",
        "        x_train_1,x_test_1=x1[train_index],x1[test_index]\n",
        "        y_train_1,y_test_1=y1[train_index],y1[test_index]\n",
        "\n",
        "        x_train_2,x_test_2=x2[train_index],x2[test_index]\n",
        "        y_train_2,y_test_2=y2[train_index],y2[test_index]\n",
        "\n",
        "        y_train = tf.keras.utils.to_categorical(y_train, num_classes = 3)\n",
        "        y_test = tf.keras.utils.to_categorical(y_test, num_classes = 3)\n",
        "        model1.fit([x_train, x_train_1,x_train_2], y_train,batch_size=batch_size,\n",
        "                            epochs=epochs,\n",
        "                            validation_data=([x_test,x_test_1,x_test_2],y_test),\n",
        "                            callbacks=[callback_2])\n",
        "        model1 = load_model(floder_path +str(subject)+'__'+str(model_file)+'.h5')\n",
        "        #scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "        #print(scores)\n",
        "        #print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "        #   print(\"***************************************************\\n\")\n",
        "        loss,accuracy,precision,recall_1=model1.evaluate([x_test,x_test_1,x_test_2],y_test)\n",
        "        print('kf_fold',i,\" \", 'loss',loss,'Accurary',accuracy,'Precision',precision,'Recall',recall_1)\n",
        "        i=i+1\n",
        "        accuracy_v.append(accuracy)\n",
        "    return accuracy_v,sum(accuracy_v)/10"
      ],
      "metadata": {
        "id": "gKfDZETSb6gV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "a302e172-cfd1-4027-e6b9-a38d8d0da19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"\\n        #accuracy.append(scores[1] * 100)\\n        #loss_per_fold.append(scores[0])\\n\\n        y_pred = model1.predict(x_test)\\n        pred_probs.extend(y_pred)\\n        fin_lst = []\\n        for i in y_pred:\\n            fin_lst.append(np.argmax(i, axis=0))\\n\\n        fin_lst = np.array(fin_lst)\\n        fin_lst = fin_lst.reshape((-1,1))\\n    #     y_hat = np.array(y_pred >= 0.5, dtype = int)\\n        #true_labels.extend(y[test])\\n        y_true.extend(y_test)\\n        y_predict.extend(fin_lst)\\n\\n\\n        # Increase fold number\\n        fold_no = fold_no + 1\\n\\n    ly_test = label_binarize(y_true, classes=[0, 1, 2])\\n    test_yhat = label_binarize(y_predict, classes=[0, 1, 2])\\n    n_classes = 3\\n    fpr = dict()\\n    tpr = dict()\\n    roc_auc = dict()\\n    for i in range(n_classes):\\n        fpr[i], tpr[i], _ = roc_curve(ly_test[:, i], test_yhat[:, i])\\n        roc_auc[i] = auc(fpr[i], tpr[i])\\n\\n    # Compute micro-average ROC curve and ROC area\\n    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(ly_test.ravel(), test_yhat.ravel())\\n    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\\n\\n    # First aggregate all false positive rates\\n    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\\n\\n    # Then interpolate all ROC curves at this points\\n    mean_tpr = np.zeros_like(all_fpr)\\n    for i in range(n_classes):\\n        mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\\n\\n    # Finally average it and compute AUC\\n    mean_tpr /= n_classes\\n\\n    fpr[\"macro\"] = all_fpr\\n    tpr[\"macro\"] = mean_tpr\\n    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\\n\\n    # Plot all ROC curves\\n    #plt.figure()\\n\\n    plt.plot(\\n        fpr[\"macro\"],\\n        tpr[\"macro\"],\\n        label=\"(area = {0:0.2f})\".format(roc_auc[\"macro\"]),\\n        color=\"red\",\\n        linewidth=4,\\n    )\\n\\n    plt.plot([0, 1], [0, 1], \"k--\", lw=2)\\n    plt.xlim([0.0, 1.0])\\n    plt.ylim([0.0, 1.05])\\n    plt.xlabel(\"False Positive Rate\")\\n    plt.ylabel(\"True Positive Rate\")\\n    # plt.title(\"Some extension of Receiver operating characteristic to multiclass\")\\n    plt.legend(loc=\"lower right\")\\n    plt.savefig(floder_path +str(subject)+\\'__\\'+str(model_file)+\\'__\\'+\\'.png\\')\\n    plt.show()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ra68T071SlYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##subject"
      ],
      "metadata": {
        "id": "IwG8GEnlSl68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coc_1=pd.read_csv('/content/Final_data_Split/Subject1/COCO.csv')\n",
        "img_1=pd.read_csv('/content/Final_data_Split/Subject1/ImageNet.csv')\n",
        "sun_1=pd.read_csv('/content/Final_data_Split/Subject1/SUN.csv')\n"
      ],
      "metadata": {
        "id": "1SiWnRUySneJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sun_1 = interpolation(sun_1)\n",
        "\n",
        "sun_1.columns = ['img1', 'img2', 'img3', 'img4', 'img5', 'img6', 'img7', 'img8', 'img9',\n",
        "       'img10', 'img11', 'img12', 'img13', 'img14', 'img15', 'img16']\n",
        "sun_1"
      ],
      "metadata": {
        "id": "LXHEn3DRSqMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('/content/out1')\n",
        "batch=8"
      ],
      "metadata": {
        "id": "SDV9a2khSsHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_9GjoVlSuNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**COCO_vs_sun**"
      ],
      "metadata": {
        "id": "jH7J0o_ySuYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_c=coc_1.iloc[:,:16]\n",
        "df_c['label']=0 #COCO\n",
        "\n",
        "df_s=sun_1.iloc[:,:16]\n",
        "df_s['label']=1 #SUN\n",
        "df_C_S=pd.concat([df_c,df_s])\n",
        "df_C_S=res_ind(df_C_S)\n"
      ],
      "metadata": {
        "id": "2EzhJBs3SuYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=mark_img(df_C_S)\n",
        "x.shape,y.shape"
      ],
      "metadata": {
        "id": "YgTGyMUiSuYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1,y1=gram_diff(df_C_S)\n",
        "x1.shape,y1.shape\n"
      ],
      "metadata": {
        "id": "7CMfV2lmiodb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2,y2=gram_summ(df_C_S)\n",
        "x1.shape,y1.shape"
      ],
      "metadata": {
        "id": "eOdH3s9sBEP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Model_par_two()\n",
        "kf=10\n",
        "floder_path='/content/out1/'\n",
        "model_file='model_coco_vs_sun'\n",
        "Kfloding(kf,model_1,x,y,x1,y1,x2,y2,floder_path,model_file,'subject_1',20,batch)\n"
      ],
      "metadata": {
        "id": "vMdOdTtMSuYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z1aQC83WSw-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Imagenet_vs_sun**"
      ],
      "metadata": {
        "id": "19OqTa1KSxKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_i=img_1.iloc[:,:16]\n",
        "df_i['label']=0 #COCO\n",
        "\n",
        "df_s=sun_1.iloc[:,:16]\n",
        "df_s['label']=1 #SUN\n",
        "df_I_S=pd.concat([df_i,df_s])\n",
        "df_I_S=res_ind(df_I_S)\n"
      ],
      "metadata": {
        "id": "SskVtXk3SxKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=mark_img(df_I_S)\n",
        "x.shape,y.shape"
      ],
      "metadata": {
        "id": "-6oRbdbySxKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1,y1=gram_diff(df_I_S)\n",
        "x1.shape,y1.shape\n"
      ],
      "metadata": {
        "id": "aS1eqp1LlgXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2,y2=gram_summ(df_I_S)\n",
        "x2.shape,y2.shape\n"
      ],
      "metadata": {
        "id": "W5G0OPlsBjT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf=10\n",
        "floder_path='/content/out1/'\n",
        "model_file='model_image_vs_sun'\n",
        "model_1 = Model_par_two()\n",
        "Kfloding(kf,model_1,x,y,x1,y1,x2,y2,floder_path,model_file,'subject_1',20,batch)"
      ],
      "metadata": {
        "id": "qo37P-7ESxKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GVu_LASiSyjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**coco_vs_imagenet**\n"
      ],
      "metadata": {
        "id": "NM-6ScwsSytp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_i=img_1.iloc[:,:16]\n",
        "df_i['label']=0 #COCO\n",
        "\n",
        "df_c=coc_1.iloc[:,:16]\n",
        "df_c['label']=1 #SUN\n",
        "df_I_C=pd.concat([df_i,df_c])\n",
        "df_I_C=res_ind(df_I_C)\n"
      ],
      "metadata": {
        "id": "qcYH5_TFSytq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=mark_img(df_I_C)\n",
        "x.shape,y.shape"
      ],
      "metadata": {
        "id": "1xSnlj3aSytr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1,y1=gram_diff(df_I_C)\n",
        "x1.shape,y1.shape"
      ],
      "metadata": {
        "id": "_WkDj8kqliiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2,y2=gram_summ(df_I_C)\n",
        "x2.shape,y2.shape"
      ],
      "metadata": {
        "id": "P0zv7CYzB8jJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf=10\n",
        "floder_path='/content/out1/'\n",
        "model_file='model_coco_vs_imagenet'\n",
        "model_1 = Model_par_two()\n",
        "Kfloding(kf,model_1,x,y,x1,y1,x2,y2,floder_path,model_file,'subject_1',50,batch)"
      ],
      "metadata": {
        "id": "BAhAkg35Sytu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "msj0FZ-fS0TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###coco_vs_imagenet_vs_sun"
      ],
      "metadata": {
        "id": "sTDcpVawS0eM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_c=coc_1.iloc[:,:16]\n",
        "df_c['label']=0\n",
        "df_i=img_1.iloc[:,:16]\n",
        "df_i['label']=1\n",
        "df_s=sun_1.iloc[:,:16]\n",
        "df_s['label']=2\n",
        "df_total=pd.concat([df_i,df_c,df_s])\n",
        "df_total=res_ind(df_total)\n",
        "dat = df_total.copy()"
      ],
      "metadata": {
        "id": "M72MFEvpS0eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y=mark_img(dat)\n",
        "x.shape,y.shape"
      ],
      "metadata": {
        "id": "vk_aGokeS0eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1,y1=gram_diff(dat)\n",
        "x1.shape,y1.shape"
      ],
      "metadata": {
        "id": "7raYs44NlkpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2,y2=gram_summ(dat)\n",
        "x2.shape,y2.shape"
      ],
      "metadata": {
        "id": "73qdO73ECIYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model_1 = Model_1()\n",
        "kf=10\n",
        "floder_path='/content/out1/'\n",
        "model_file='model_coco_vs_imagenet_sun'\n",
        "\n",
        "model_1 = Model_par_three()\n",
        "kf_flod_three(kf,x,y,x1,y1,x2,y2,model_1,floder_path,model_file,'subject_1',50,batch)"
      ],
      "metadata": {
        "id": "rox38KGrS0eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jNUxsZTc8qZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l5wCOdhNoyk6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}